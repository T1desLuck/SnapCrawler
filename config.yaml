# Конфигурация SnapCrawler (по умолчанию)

# Раздел проекта и общие цели
project:
  name: "SnapCrawler"             # Имя проекта (для логов/отчетов)
  storage_path: "./dataset"       # Папка для сохранения изображений (БД будет в корне проекта)
  max_folder_size_mb: 0           # Лимит размера папки (в МБ). 0 = без ограничений
  target_images: 150000           # Целевое число изображений для сбора. 0 = без лимита
  statistics_enabled: true        # Собирать базовую статистику (в БД/логах)

# Правила фильтрации и предобработки изображений
image:
  min_side: 384                    # Временно снизим для пропускной способности
  accept_bw: true                  # Временно принимаем ч/б, чтобы не терять
  extensions: []                   # Диагностика: не ограничиваем расширениями
  orientation: "all"               # Ориентация: all|square|portrait|landscape
  save_format: "original"          # "jpeg" | "original" — сохранить как JPEG либо в исходном формате
  jpeg_quality: 100                # Качество JPEG при save_format: jpeg
  skip_watermarked_urls: true      # На старте отключим, чтобы не потерять источники; потом можно включить
  watermark_keywords:              # Слова в URL, по которым считаем, что там водяной знак/превью
    - watermark
    - wm
  watermark_pixel_filter:         # Простой пиксельный фильтр водяных знаков (по краям)
    enable: false
    band_ratio: 0.15
    edge_threshold: 25
    edge_density: 0.08
  # URL-фильтр по ключевым словам для скриншотов/гайдов (часто ведут на не-фото)
  skip_screenshot_urls: true
  screenshot_keywords:
    - screenshot
    - screen
  # Простая эвристика распознавания скриншотов по пикселям (заголовочные полосы/текстовые края)
  screenshot_pixel_filter:
    enable: false                  # Диагностика: выключаем, чтобы понять потолок сохранений
    top_band_ratio: 0.06         # Доля высоты для проверки ровной верхней полосы (титл-бар)
    top_band_var_max: 12.0       # Максимальная дисперсия в верхней полосе (низкая = почти ровный цвет)
    edge_threshold: 28           # Порог градиента для подсчёта краёв
    edge_density_center: 0.18    # Порог плотности «текстовых» краёв в центральной области

  # URL-фильтр логотипов/иконок
  skip_logo_urls: true
  logo_keywords:
    - logo
    - favicon
    - icon
    - header-logo
  # Эвристика для логотипов с альфа-каналом (полупрозрачный/прозрачный фон)
  logo_alpha_filter:
    enable: false                  # Диагностика: выключаем
    alpha_threshold: 24         # Порог прозрачности (0..255): <= считаем прозрачным
    transparent_fraction: 0.30  # Если доля прозрачных пикселей выше — отбрасываем

# Настройки нейросетевого фильтра (опционально). Если модели нет — автодеактивация.
classifier:
  enable: false                   # Диагностика: выключено
  model_path: "./models/photo_filter.onnx"  # Путь к ONNX‑модели
  batch_size: 16                  # (Сейчас без эффекта: батч‑инференс не реализован)
  threshold: 0.5                  # Порог уверенности (0..1). Ниже — отбрасываем
  parallel: true                  # [зарезервировано] запуск в отдельном процессе (не используется)
  enable_ssim: false              # [зарезервировано] SSIM‑постфильтр (не используется)
  auto_download: false            # Не скачиваем модель автоматически (отключено)
  download_url: ""                # Прямая ссылка на .onnx (задайте, если включили auto_download)

# Дедупликация (по pHash)
deduplication:
  enable: true                     # Включить проверку дубликатов (визуально похожих)
  hamming_threshold: 5             # Порог расстояния Хэмминга: <5 — считаем дубликатом

# Загрузка и парсинг источников
download:
  threads: 10                            # Больше потребителей для диагностики
  deep_parsing: true                     # Глубокий парсинг ссылок <a> в пределах домена (BFS)
  deep_max_depth: 10                      # Максимальная глубина обхода при deep_parsing (BFS по домену)
  allow_subdomains: true                 # Разрешать переход на поддомены того же сайта при BFS
  per_site_concurrency: 1                # Параллельные запросы на один домен (стелс)
  enable_auto_discovery: true            # [зарезервировано] автообнаружение (sitemap/RSS) — не используется
  request_delay: 1.0                     # Немного ускорим (с джиттером)
  max_requests_per_site: 2000            # Лимит запросов на один домен (меньше — меньше риск бана)
  # Конфигурация сетевых таймаутов и повторов
  page_timeout: 15                       # Чуть быстрее фэйлится
  image_timeout: 20                      # Чуть быстрее фэйлится
  image_retries: 2                       # Меньше повторов, чтобы не зависать
  backoff_base: 2.0                      # Основание экспоненциальной задержки между повторами (2^n)
  collector_conn_limit: 12               # Ускорим обход страниц
  circuit_breaker_enabled: true          # Включить circuit breaker (пауза при 429/ошибках)
  url_collect_limit: 0                   # 0 — без лимита; иначе ограничить число собранных URL на этапе парсинга
  user_agents:                           # Ротация User‑Agent для «незаметности» (desktop+mobile)
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
    - "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_3) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Safari/605.1.15"
    - "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0"
    - "Mozilla/5.0 (Macintosh; Intel Mac OS X 13.5; rv:119.0) Gecko/20100101 Firefox/119.0"
    - "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:116.0) Gecko/20100101 Firefox/116.0"
    - "Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1"
    - "Mozilla/5.0 (Linux; Android 14; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Mobile Safari/537.36"
    - "Mozilla/5.0 (Linux; Android 13; SM-G996B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Mobile Safari/537.36"
    - "Mozilla/5.0 (iPad; CPU OS 16_7 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.7 Mobile/15E148 Safari/604.1"
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:118.0) Gecko/20100101 Firefox/118.0"
    - "Mozilla/5.0 (Macintosh; Intel Mac OS X 12_6_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36"
    - "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    - "Mozilla/5.0 (Linux; Android 12; Mi 11) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Mobile Safari/537.36"
    - "Mozilla/5.0 (iPhone; CPU iPhone OS 16_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.5 Mobile/15E148 Safari/604.1"
  proxies: []                            # [зарезервировано] список прокси (не используется в текущей версии)
  sources:
    - "https://unsplash.com"
    - "https://www.pexels.com"
    - url: "https://pixabay.com/photos"
      deep: true
      max_depth: 20
    - "https://commons.wikimedia.org"

# Настройки CLIP zero-shot (ONNX) для пост-фильтра
clip:
  repo_id: "openai/clip-vit-base-patch32"     # Репозиторий на HuggingFace
  model_filename: "onnx/model.onnx"           # Большой объединённый ONNX (визуал+текст)
  tokenizer_filename: "tokenizer.json"        # Токенайзер CLIP
  cache_dir: "./models/clip"                  # Куда кэшировать веса
  revision: "12b36594d53414ecfba93c7200dbb7c7db3c900a"  # Коммит, где точно есть onnx/model.onnx
  prompts: ["a photo", "a painting", "an illustration", "a 3D render", "AI generated image", "a cartoon"]
  positive_index: 0                           # Индекс позитивного класса в списке prompts
  # Inline-фильтр CLIP (до сохранения). Если включить — не-фото будут отбрасываться в рантайме
  enable_filter: false            # Диагностика: выключено
  threshold: 0.60

# Упаковка датасета
packing:
  format: "zip"                   # Формат архива: zip|tar
  auto_pack: true                 # Авто‑совет упаковать при превышении лимита

# Пост‑фильтр уже скачанных изображений (очистка ИИ/арт/не‑фото)
postfilter:
  enable: true                 # Включить пост-фильтр после загрузки
  dry_run: true                # Сначала прогон без удаления
  threshold: 0.60              # Порог (0..1) комбинированного скора
  scan_limit: 0                # 0 — без лимита; иначе ограничить кол-во проверок
  use_classifier: false        # Не используем legacy‑классификатор
  use_clip: true               # Использовать CLIP zero-shot для очистки
